{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Feature Eng Cyclical\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[crim: double, zn: double, indus: double, chas: int, nox: double, rm: double, age: double, dis: double, rad: int, tax: int, ptratio: double, b: double, lstat: double, medv: double]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "house_df = spark.read.csv(\"file://%s/../datasets/BostonHousing.csv\" % cwd, header=True, inferSchema=True)\n",
    "house_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COL=\"medv\"\n",
    "FEATURES_COL=\"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              medv|\n",
      "+-------+------------------+\n",
      "|  count|               506|\n",
      "|   mean|22.532806324110698|\n",
      "| stddev| 9.197104087379815|\n",
      "|    min|               5.0|\n",
      "|    max|              50.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "house_df.describe(LABEL_COL).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crim\t-0.39\n",
      "zn\t 0.36\n",
      "indus\t-0.48\n",
      "chas\t 0.18\n",
      "nox\t-0.43\n",
      "rm\t 0.70\n",
      "age\t-0.38\n",
      "dis\t 0.25\n",
      "rad\t-0.38\n",
      "tax\t-0.47\n",
      "ptratio\t-0.51\n",
      "b\t 0.33\n",
      "lstat\t-0.74\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = list((dtype[0] for dtype in house_df.dtypes if (dtype[1] == \"double\" or dtype[1] == \"int\") and dtype[0] != LABEL_COL))\n",
    "for numerical_column in numerical_columns:\n",
    "    print(\"%s\\t%5.2f\" % (numerical_column, house_df.corr(LABEL_COL, numerical_column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[crim: double, zn: double, indus: double, chas: int, nox: double, rm: double, age: double, dis: double, rad: int, tax: int, ptratio: double, b: double, lstat: double, medv: double]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = house_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numerical_columns, outputCol=FEATURES_COL)\n",
    "lr = LinearRegression(featuresCol=FEATURES_COL, labelCol=LABEL_COL, maxIter=10)\n",
    "\n",
    "p = Pipeline(stages=[assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = p.fit(train_df)\n",
    "lr_model = model.stages[-1]\n",
    "\n",
    "summary = lr_model.summary\n",
    "print(\"RMSE:\\t%.2f\\nR2:\\t%.2f\" % (summary.rootMeanSquaredError, summary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t4.73\n",
      "R2:\t0.74\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=LABEL_COL, metricName=\"rmse\")\n",
    "r2_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=LABEL_COL, metricName=\"r2\")\n",
    "\n",
    "print(\"RMSE:\\t%.2f\\nR2:\\t%.2f\" % (rmse_evaluator.evaluate(predictions), r2_evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param grid size: 12\n",
      "RMSE:\t4.63\n",
      "R2:\t0.75\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "param_grid = (ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.1, 0.01])\n",
    "    .addGrid(lr.fitIntercept, [False, True])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"Param grid size: %d\" % len(param_grid))\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=p,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=rmse_evaluator,\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "tuned_model = tvs.fit(train_df)\n",
    "tuned_predictions = tuned_model.transform(test_df)\n",
    "\n",
    "print(\"RMSE:\\t%.2f\\nR2:\\t%.2f\" % (rmse_evaluator.evaluate(tuned_predictions), r2_evaluator.evaluate(tuned_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
